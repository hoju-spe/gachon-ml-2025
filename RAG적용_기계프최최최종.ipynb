{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "49d55cc8c830427db85c73573133a41c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1fda74862ed4c9e8f3d8d52cd957079",
              "IPY_MODEL_530be36b5d564aebb7b916e5466c2d4b",
              "IPY_MODEL_4a161f2ac8934f969aa9cd599716cd8e"
            ],
            "layout": "IPY_MODEL_61e6e2a076be4573b3cab0599722e04f"
          }
        },
        "b1fda74862ed4c9e8f3d8d52cd957079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75ad5ac4a24d455682a3ff19b1022a9e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d8b8655aa21543e8a369dd185016e3e8",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "530be36b5d564aebb7b916e5466c2d4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd5b7b250804477297f34be6dc64bbc3",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e1ed38114a349b592fafa7c24e2cb45",
            "value": 2
          }
        },
        "4a161f2ac8934f969aa9cd599716cd8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3735318595be4907ac59f9d6a917d83a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c515333786ab42019718a4f2ded902d3",
            "value": "‚Äá2/2‚Äá[00:26&lt;00:00,‚Äá12.90s/it]"
          }
        },
        "61e6e2a076be4573b3cab0599722e04f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75ad5ac4a24d455682a3ff19b1022a9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8b8655aa21543e8a369dd185016e3e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd5b7b250804477297f34be6dc64bbc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e1ed38114a349b592fafa7c24e2cb45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3735318595be4907ac59f9d6a917d83a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c515333786ab42019718a4f2ded902d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoju-spe/gachon-ml-2025/blob/main/RAG%EC%A0%81%EC%9A%A9_%EA%B8%B0%EA%B3%84%ED%94%84%EC%B5%9C%EC%B5%9C%EC%B5%9C%EC%A2%85.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "#  300Í∞ú ÌïôÏäµÎç∞Ïù¥ÌÑ∞ ÏûêÎèô ÏÉùÏÑ±Í∏∞ (JSONL)\n",
        "# ==========================================\n",
        "from openai import OpenAI\n",
        "import json\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"ÌÇ§\"\n",
        "client = OpenAI()\n",
        "\n",
        "def generate_sample():\n",
        "    prompt = \"\"\"\n",
        "Îã§Ïùå ÌòïÏãùÏùò Î©¥Ï†ë ÌïôÏäµ Îç∞Ïù¥ÌÑ∞Î•º ÌïòÎÇò ÏÉùÏÑ±ÌïòÏÑ∏Ïöî.\n",
        "\n",
        "ÌòïÏãù(JSON):\n",
        "{\n",
        " \"instruction\": \"Î©¥Ï†ë ÏßàÎ¨∏\",\n",
        " \"input\": \"ÏõêÎ≥∏ ÎãµÎ≥Ä\",\n",
        " \"output\": \"STAR Í∏∞Î∞ò Í∞úÏÑ† ÎãµÎ≥Ä\"\n",
        "}\n",
        "\n",
        "Ï°∞Í±¥:\n",
        "- ÏßàÎ¨∏ÏùÄ Ïã§Ï†ú Î©¥Ï†ëÏóêÏÑú ÏûêÏ£º ÎÇòÏò§Îäî ÏßàÎ¨∏Ïùº Í≤É\n",
        "- ÏõêÎ≥∏ ÎãµÎ≥ÄÏùÄ ‚ÄòÎ∂ÄÏ°±Ìïú/ÏßßÏùÄ/Íµ¨Ï≤¥Ï†ÅÏù¥ÏßÄ ÏïäÏùÄ‚Äô ÎãµÎ≥ÄÏùº Í≤É\n",
        "- output ÏùÄ ÏõêÎ≥∏ ÎãµÎ≥ÄÎßåÏùÑ Í∏∞Î∞òÏúºÎ°ú STAR Íµ¨Ï°∞Î°ú ÌôïÏû•\n",
        "- output Ïóê ÏÉàÎ°úÏö¥ Í≤ΩÌóòÏùÑ Ï∞ΩÏûëÌïòÏßÄ Îßê Í≤É\n",
        "\"\"\"\n",
        "\n",
        "    res = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.6\n",
        "    )\n",
        "    txt = res.choices[0].message.content.strip()\n",
        "    return json.loads(txt)\n",
        "\n",
        "dataset = []\n",
        "for i in range(300):\n",
        "    print(f\"{i+1}/300 ÏÉùÏÑ±Ï§ë...\")\n",
        "    try:\n",
        "        item = generate_sample()\n",
        "        dataset.append(item)\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "with open(\"training_data.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for d in dataset:\n",
        "        f.write(json.dumps(d, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(\" training_data.jsonl ÏÉùÏÑ± ÏôÑÎ£å!\")"
      ],
      "metadata": {
        "id": "Ay0VBKCr-xVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb -q\n"
      ],
      "metadata": {
        "id": "JZ4c2mUhMQ0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "\n",
        "# Chroma ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÏÉùÏÑ±\n",
        "chroma_client = chromadb.PersistentClient(path=\"/content/chroma_db\")\n",
        "\n",
        "collection = chroma_client.get_or_create_collection(\n",
        "    name=\"interview_data\",\n",
        "    metadata={\"hnsw:space\": \"cosine\"}\n",
        ")\n",
        "# collection ÏÉùÏÑ±\n",
        "collection = chroma_client.get_or_create_collection(\n",
        "    name=\"interview_data\",\n",
        "    metadata={\"hnsw:space\": \"cosine\"}\n",
        ")\n",
        "\n",
        "# JSONL Î°úÎìú\n",
        "data = []\n",
        "with open(\"/content/training_data.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        data.append(json.loads(line))\n",
        "\n",
        "# DBÏóê ÎÑ£Í∏∞\n",
        "documents = []\n",
        "metadatas = []\n",
        "ids = []\n",
        "\n",
        "for i, item in enumerate(data):\n",
        "    text = f\"\"\"\n",
        "[Î©¥Ï†ë ÏßàÎ¨∏] {item['instruction']}\n",
        "[ÏßßÏùÄ ÎãµÎ≥Ä] {item['input']}\n",
        "[STAR ÌôïÏû• ÎãµÎ≥Ä] {item['output']}\n",
        "\"\"\"\n",
        "    documents.append(text)\n",
        "    metadatas.append({\"category\": \"interview\"})\n",
        "    ids.append(str(i))\n",
        "\n",
        "collection.add(\n",
        "    documents=documents,\n",
        "    metadatas=metadatas,\n",
        "    ids=ids\n",
        ")\n",
        "\n",
        "print(\"300Í∞ú Îç∞Ïù¥ÌÑ∞ ChromaDB Ï†ÄÏû• ÏôÑÎ£å!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5NJBlDtMYQn",
        "outputId": "2c9b1754-bc2f-4640-8928-24060fa9cd7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üî• 300Í∞ú Îç∞Ïù¥ÌÑ∞ ChromaDB Ï†ÄÏû• ÏôÑÎ£å!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_similar_answers(query, top_k=3):\n",
        "    results = collection.query(\n",
        "        query_texts=[query],\n",
        "        n_results=top_k\n",
        "    )\n",
        "\n",
        "    retrieved = []\n",
        "    for doc in results[\"documents\"][0]:\n",
        "        retrieved.append(doc)\n",
        "\n",
        "    return \"\\n\\n---\\n\\n\".join(retrieved)\n"
      ],
      "metadata": {
        "id": "WjQHBTsVNZFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ÌïÑÏàò ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§Ïπò\n",
        "!pip install gradio openai transformers accelerate bitsandbytes chromadb -q\n",
        "\n",
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "from transformers import BitsAndBytesConfig, AutoTokenizer, AutoModelForCausalLM\n",
        "import chromadb\n",
        "import torch\n",
        "import os\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "#  OpenAI API ÌÇ§\n",
        "# ==========================================\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"ÌÇ§\"\n",
        "client = OpenAI()\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "#  ChromaDB (RAG) Ï¥àÍ∏∞Ìôî\n",
        "# ==========================================\n",
        "chroma_client = chromadb.PersistentClient(path=\"/content/chroma_db\")\n",
        "\n",
        "collection = chroma_client.get_or_create_collection(\n",
        "    name=\"interview_data\",\n",
        "    metadata={\"hnsw:space\": \"cosine\"}\n",
        ")\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "#  Qwen 2.5-3B-Instruct Î°úÎìú (Í∞êÏ†ï Î∂ÑÏÑùÏö©)\n",
        "# ==========================================\n",
        "MODEL_ID = \"Qwen/Qwen2.5-3B-Instruct\"\n",
        "\n",
        "print(\" Qwen 2.5 3B Î™®Îç∏ Î°úÎî© Ï§ë... (4bit ÏñëÏûêÌôî)\")\n",
        "\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    llm_int8_enable_fp32_cpu_offload=True\n",
        ")\n",
        "\n",
        "# ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Î°úÎìú Î∂ÄÎ∂Ñ\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    quantization_config=quant_config,\n",
        "    device_map={\"\": \"cuda\"}  # GPUÏóê Í∞ïÏ†úÎ°ú Ïò¨Î¶º\n",
        ")\n",
        "print(\" Î™®Îç∏ Î°úÎî© ÏôÑÎ£å!\")\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "#  RAG Í≤ÄÏÉâ Ìï®Ïàò\n",
        "# ==========================================\n",
        "def retrieve_similar_answers(query, top_k=3):\n",
        "    try:\n",
        "        results = collection.query(\n",
        "            query_texts=[query],\n",
        "            n_results=top_k\n",
        "        )\n",
        "        docs = results.get(\"documents\", [[]])[0]\n",
        "        return \"\\n\\n---\\n\\n\".join(docs)\n",
        "    except:\n",
        "        return \"(RAG Í≤ÄÏÉâ Ïã§Ìå®, DB ÎπÑÏñ¥ ÏûàÏùå)\"\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "#  Í∞êÏ†ï Î∂ÑÏÑù (Qwen 2.5 3B Î°úÏª¨ LLM)\n",
        "# ==========================================\n",
        "def analyze_sentiment_local(text):\n",
        "    # 1. ÏãúÏä§ÌÖú ÌîÑÎ°¨ÌîÑÌä∏Î°ú Í∞ïÌïòÍ≤å Ï†úÏïΩ (ÏÇ¨Ï°± Í∏àÏßÄ, Î¨∏Ïû• ÏôÑÏÑ±)\n",
        "    system_message = \"\"\"ÎãπÏã†ÏùÄ ÎÉâÏ≤†Ìïú Î©¥Ï†ëÍ¥ÄÏûÖÎãàÎã§. ÏßÄÏõêÏûêÏùò ÎãµÎ≥ÄÏùÑ Î∂ÑÏÑùÌïòÏÑ∏Ïöî.\n",
        "Í∑úÏπô:\n",
        "1. 'Ï†ïÎ≥¥Í∞Ä Î∂ÄÏ°±ÌïòÎã§'Í±∞ÎÇò 'Ï∂îÏ∏°ÌïúÎã§'Îäî ÎßêÏùÄ Ï†àÎåÄ ÌïòÏßÄ ÎßàÏÑ∏Ïöî.\n",
        "2. Ï£ºÏñ¥ÏßÑ ÌÖçÏä§Ìä∏ÎßåÏúºÎ°ú ÌåêÎã®ÌïòÏÑ∏Ïöî.\n",
        "3. Í∞Å Ìï≠Î™©Ïùò Î¨∏Ïû•ÏùÄ Î∞òÎìúÏãú ÏôÑÍ≤∞Îêú Î¨∏Ïû•ÏúºÎ°ú ÎÅùÎÇ¥ÏÑ∏Ïöî.\n",
        "4. ÏïÑÎûò ÌòïÏãùÏùÑ ÏóÑÍ≤©Ìûà ÏßÄÌÇ§ÏÑ∏Ïöî.\n",
        "\n",
        "ÌòïÏãù:\n",
        "tone: (Í∞êÏ†ï ÌÜ§)\n",
        "confidence: (ÏûêÏã†Í∞ê ÏàòÏ§Ä)\n",
        "positive: (Í∏çÏ†ïÏ†ÅÏù∏ Ï†ê)\n",
        "negative: (ÏïÑÏâ¨Ïö¥ Ï†ê)\n",
        "summary: (Ï¥ùÌèâ)\"\"\"\n",
        "\n",
        "    user_message = f\"ÎãµÎ≥Ä: {text}\\n\\nÏúÑ ÎãµÎ≥ÄÏùÑ Î∂ÑÏÑùÌï¥.\"\n",
        "\n",
        "    # QwenÏùò Ï±ÑÌåÖ ÌÖúÌîåÎ¶ø Ï†ÅÏö© (ÏßÄÏãú Ïù¥ÌñâÎ†• ÏÉÅÏäπ)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        "    text_input = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    model_inputs = tokenizer([text_input], return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(\n",
        "            **model_inputs,\n",
        "            max_new_tokens=512,  # 200 -> 512 (Î¨∏Ïû• ÎÅäÍπÄ Î∞©ÏßÄ)\n",
        "            do_sample=True,\n",
        "            top_p=0.9,\n",
        "            temperature=0.3,\n",
        "            repetition_penalty=1.1 # Î∞òÎ≥µ Î∞©ÏßÄ\n",
        "        )\n",
        "\n",
        "    # ÏûÖÎ†• ÌîÑÎ°¨ÌîÑÌä∏ Î∂ÄÎ∂Ñ ÏûòÎùºÎÇ¥Í∏∞\n",
        "    generated_ids = [\n",
        "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "    ]\n",
        "\n",
        "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "    return response.strip()\n",
        "\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "#  STAR ÌôïÏû• (GPT-4o-mini + RAG)\n",
        "# ==========================================\n",
        "def improve_answer_star(question, answer):\n",
        "    rag_context = retrieve_similar_answers(question)\n",
        "\n",
        "    system_prompt = \"ÎãπÏã†ÏùÄ STAR/PMI Í∏∞Î∞òÏùò Ï†ÑÎ¨∏ Î©¥Ï†ë ÏΩîÏπòÏûÖÎãàÎã§.\"\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "Î©¥Ï†ë ÏßàÎ¨∏: {question}\n",
        "ÏÇ¨Ïö©Ïûê ÎãµÎ≥Ä: {answer}\n",
        "\n",
        "[RAG Ï∞∏Í≥† ÏÇ¨Î°Ä]\n",
        "{rag_context}\n",
        "\n",
        "ÏïÑÎûò Ï°∞Í±¥Ïóê ÎßûÍ≤å Î©¥Ï†ë ÎãµÎ≥ÄÏùÑ STAR Íµ¨Ï°∞Î°ú ÏûêÏó∞Ïä§ÎüΩÍ≤å ÌôïÏû•ÌïòÏÑ∏Ïöî.\n",
        "\n",
        "Ï°∞Í±¥:\n",
        "- Í≤ΩÌóò Ï∞ΩÏûë Í∏àÏßÄ (ÏÇ¨Ïö©Ïûê ÎãµÎ≥Ä Î≤îÏúÑ ÎÇ¥ÏóêÏÑú ÌôïÏû•)\n",
        "- STAR(ÏÉÅÌô©-Í≥ºÏ†ú-ÌñâÎèô-Í≤∞Í≥º) Íµ¨Ï°∞ Ïú†ÏßÄ\n",
        "- Î¨∏Ïû• Ïàò 6~10Í∞ú\n",
        "- Î©¥Ï†ëÍ¥ÄÏù¥ Îì£Í∏∞ Ï¢ãÏùÄ ÌòÑÏã§Ï†ÅÏù∏ Î∞©ÏãùÏúºÎ°ú ÏûëÏÑ±\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "#  ÌÜµÌï© Ìï®Ïàò\n",
        "# ==========================================\n",
        "def run_all(question, answer):\n",
        "    if not question or not answer:\n",
        "        return \"ÏßàÎ¨∏Í≥º ÎãµÎ≥ÄÏùÑ ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.\", \"ÏûÖÎ†• ÎåÄÍ∏∞ Ï§ë...\"\n",
        "\n",
        "    improved = improve_answer_star(question, answer)     # GPT-4o-mini\n",
        "    sentiment = analyze_sentiment_local(answer)          # Qwen 2.5 3B\n",
        "    return improved, sentiment\n",
        "\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "#  Gradio UI\n",
        "# ==========================================\n",
        "with gr.Blocks(title=\"AI Î©¥Ï†ë Ïä§ÌîºÏπò ÏΩîÏπò PICO\") as demo:\n",
        "\n",
        "    gr.Markdown(\"# üé§ AI Î©¥Ï†ë Ïä§ÌîºÏπò ÏΩîÏπò PICO\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            q_input = gr.Textbox(label=\"Î©¥Ï†ë ÏßàÎ¨∏\", lines=2, placeholder=\"Ïòà: Î≥∏Ïù∏Ïùò Í∞ïÏ†êÏùÄ Î¨¥ÏóáÏù∏Í∞ÄÏöî?\")\n",
        "            a_input = gr.Textbox(label=\"ÎÇòÏùò ÎãµÎ≥Ä\", lines=10, placeholder=\"ÎãµÎ≥ÄÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî.\")\n",
        "            btn = gr.Button(\"‚ú® Î∂ÑÏÑù Î∞è Ï≤®ÏÇ≠ Î∞õÍ∏∞\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            a_output = gr.Textbox(label=\"AI ÏàòÏ†ï ÎãµÎ≥Ä (STAR)\", lines=12)\n",
        "            s_output = gr.Textbox(label=\"Î©¥Ï†ëÍ¥Ä Ïã¨Î¶¨/Í∞êÏ†ï Î∂ÑÏÑù\", lines=12)\n",
        "\n",
        "    btn.click(\n",
        "        fn=run_all,\n",
        "        inputs=[q_input, a_input],\n",
        "        outputs=[a_output, s_output]\n",
        "    )\n",
        "\n",
        "print(\"üåê Web UI Ïã§Ìñâ Ï§ë‚Ä¶\")\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737,
          "referenced_widgets": [
            "49d55cc8c830427db85c73573133a41c",
            "b1fda74862ed4c9e8f3d8d52cd957079",
            "530be36b5d564aebb7b916e5466c2d4b",
            "4a161f2ac8934f969aa9cd599716cd8e",
            "61e6e2a076be4573b3cab0599722e04f",
            "75ad5ac4a24d455682a3ff19b1022a9e",
            "d8b8655aa21543e8a369dd185016e3e8",
            "dd5b7b250804477297f34be6dc64bbc3",
            "1e1ed38114a349b592fafa7c24e2cb45",
            "3735318595be4907ac59f9d6a917d83a",
            "c515333786ab42019718a4f2ded902d3"
          ]
        },
        "id": "IdMCFFDY-aRH",
        "outputId": "a9f77ad1-b08c-45aa-fdf6-93f588402ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Qwen 2.5 3B Î™®Îç∏ Î°úÎî© Ï§ë... (4bit ÏñëÏûêÌôî)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49d55cc8c830427db85c73573133a41c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Î™®Îç∏ Î°úÎî© ÏôÑÎ£å!\n",
            "üåê Web UI Ïã§Ìñâ Ï§ë‚Ä¶\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://db29d493283cf21229.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://db29d493283cf21229.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://db29d493283cf21229.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}